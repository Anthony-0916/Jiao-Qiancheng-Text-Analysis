{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439f98e7",
   "metadata": {},
   "source": [
    "# WEEK13 道德词典&情感词典"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad42dd5",
   "metadata": {},
   "source": [
    "### 1.课堂示例 2.个人文本演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd0446",
   "metadata": {},
   "source": [
    "“词典方法”（dictionary method）是一种自然语言处理（NLP）技术，用于通过查找预定义的词典或词表中的单词来分析文本。这种方法的基本思路是将文本中的单词与词典中的词条进行匹配，从而识别和提取有用的信息。词典方法通常用于情感分析、实体识别、文本分类等任务。下面是词典方法的主要特点和应用：\n",
    "\n",
    "主要特点：\n",
    "\n",
    "1.预定义词典：词典方法依赖于一个或多个预先定义好的词典，这些词典包含了目标词汇及其对应的标签或类别信息。\n",
    "\n",
    "2.匹配和提取：通过简单的匹配算法，文本中的单词与词典中的词条进行比较，识别出词典中存在的单词。\n",
    "\n",
    "3.规则简单：相对于复杂的机器学习算法，词典方法实现简单，且计算效率高。\n",
    "\n",
    "4.易于解释：由于使用了明确的词典，分析结果通常易于解释，便于理解和验证。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b71c85",
   "metadata": {},
   "source": [
    "## 1.课堂示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0bd91",
   "metadata": {},
   "source": [
    "### 道德词典 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a227ed2",
   "metadata": {},
   "source": [
    "道德词典（Moral Dictionary）是一种专门用于分析文本中的道德内容和伦理倾向的词典。它包含与道德和伦理相关的词汇，通过这些词汇的匹配和统计，可以识别和量化文本中涉及的道德主题和情感。道德词典在心理学、社会学、政治学以及计算社会科学等领域有广泛的应用，特别是在研究社会价值观、文化差异和道德情感方面。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e2657",
   "metadata": {},
   "source": [
    "道德词典的构建\n",
    "\n",
    "    词汇选择：\n",
    "         基础词汇：选择一些与道德和伦理相关的基本词汇，如“正义”、“诚实”、“慈悲”等。\n",
    "         扩展词汇：扩展基础词汇，包含同义词、反义词以及相关的词组和短语。\n",
    "            \n",
    "    分类和标注：\n",
    "         道德分类：将词汇按照道德主题进行分类，如公平、公正、忠诚、关怀、权威等。\n",
    "         情感极性：标注词汇的情感极性（正面、负面或中性），以便在分析中识别情感倾向。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ba8998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moralstrength\n",
      "  Obtaining dependency information for moralstrength from https://files.pythonhosted.org/packages/00/b5/2c6054a48ce771ea0fd1b390d51f4009d5c34bc25e64f2e8207796bd242d/moralstrength-0.2.13-py3-none-any.whl.metadata\n",
      "  Downloading moralstrength-0.2.13-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting spacy (from moralstrength)\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/c4/c5/1a4556a372ce1bd53f183d583126a6535cae6baa1b09b7028faf018c8a67/spacy-3.7.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading spacy-3.7.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.11/site-packages (from moralstrength) (2.0.3)\n",
      "Collecting gsitk (from moralstrength)\n",
      "  Obtaining dependency information for gsitk from https://files.pythonhosted.org/packages/23/7c/daf14c6de09978f5fe74727774288cd6ca82e2dc66bd9f3010094425b979/gsitk-0.2.5-py3-none-any.whl.metadata\n",
      "  Downloading gsitk-0.2.5-py3-none-any.whl.metadata (715 bytes)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from moralstrength) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.11/site-packages (from moralstrength) (1.3.0)\n",
      "Requirement already satisfied: gensim in ./anaconda3/lib/python3.11/site-packages (from gsitk->moralstrength) (4.3.0)\n",
      "Requirement already satisfied: nltk in ./anaconda3/lib/python3.11/site-packages (from gsitk->moralstrength) (3.8.1)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.11/site-packages (from gsitk->moralstrength) (6.0)\n",
      "Requirement already satisfied: pytest in ./anaconda3/lib/python3.11/site-packages (from gsitk->moralstrength) (7.4.0)\n",
      "Collecting pytreebank (from gsitk->moralstrength)\n",
      "  Downloading pytreebank-0.2.7.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in ./anaconda3/lib/python3.11/site-packages (from gsitk->moralstrength) (4.12.2)\n",
      "Requirement already satisfied: lxml in ./anaconda3/lib/python3.11/site-packages (from gsitk->moralstrength) (4.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/lib/python3.11/site-packages (from pandas->moralstrength) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas->moralstrength) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/lib/python3.11/site-packages (from pandas->moralstrength) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn->moralstrength) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn->moralstrength) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn->moralstrength) (2.2.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/7a/05/4a3b5c3043c6d84c00bf0f574d326660702b1c10174fe6b44cef3c3dff08/murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/d7/f6/67babf1439cdd6d46e4e805616bee84981305c80e562320c293712f54034/cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/a8/b3/1a73ba16bab53043fd19dd0a7838ae05c705dccb329404dd4ad5925767f1/preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.2.2 from https://files.pythonhosted.org/packages/05/48/2cf60744d60d07d789ce5cf6230fe2140612bc3f8ae70a89bc980ea27a28/thinc-8.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading thinc-8.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/1b/d7/0800af1a75008b3a6a6a24f3efd165f2d2208076e9b8a4b11b66f16217f3/srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for weasel<0.4.0,>=0.1.0 from https://files.pythonhosted.org/packages/d5/e5/b63b8e255d89ba4155972990d42523251d4d1368c4906c646597f63870e2/weasel-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for typer<0.10.0,>=0.3.0 from https://files.pythonhosted.org/packages/62/39/82c9d3e10979851847361d922a373bdfef4091020da7f893acfaf07c0225/typer-0.9.4-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./anaconda3/lib/python3.11/site-packages (from spacy->moralstrength) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/lib/python3.11/site-packages (from spacy->moralstrength) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from spacy->moralstrength) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./anaconda3/lib/python3.11/site-packages (from spacy->moralstrength) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from spacy->moralstrength) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.11/site-packages (from spacy->moralstrength) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from spacy->moralstrength) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->moralstrength)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/58/70/4058ab0ebb082b18d06888e711baed7f33354a5e0b363bb627586d8c323a/langcodes-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy->moralstrength)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/12/5f/139464da89c49afcc8bb97ebad48818a535220ce01b1f24c61fb80dbe4d0/language_data-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->moralstrength) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->moralstrength) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->moralstrength) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->moralstrength) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->moralstrength) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->moralstrength) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy->moralstrength)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/a8/73/0a9d4e7f6e78ef270e3a4532b17e060a02087590cf615ba9943fd1a283e9/blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy->moralstrength)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/39/78/f9d18da7b979a2e6007bfcea2f3c8cc02ed210538ae1ce7e69092aed7b18/confection-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy->moralstrength) (8.0.4)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy->moralstrength)\n",
      "  Obtaining dependency information for cloudpathlib<0.17.0,>=0.7.0 from https://files.pythonhosted.org/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./anaconda3/lib/python3.11/site-packages (from beautifulsoup4->gsitk->moralstrength) (2.4)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in ./anaconda3/lib/python3.11/site-packages (from gensim->gsitk->moralstrength) (2.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->spacy->moralstrength) (2.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./anaconda3/lib/python3.11/site-packages (from nltk->gsitk->moralstrength) (2022.7.9)\n",
      "Requirement already satisfied: iniconfig in ./anaconda3/lib/python3.11/site-packages (from pytest->gsitk->moralstrength) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in ./anaconda3/lib/python3.11/site-packages (from pytest->gsitk->moralstrength) (1.0.0)\n",
      "Requirement already satisfied: pyfume in ./anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim->gsitk->moralstrength) (0.3.1)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->moralstrength)\n",
      "  Obtaining dependency information for marisa-trie>=0.7.7 from https://files.pythonhosted.org/packages/3f/bd/72ea1306a3c239866ec39496fcb384c9c410ef1dcfdbcb06ec853592869b/marisa_trie-1.1.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading marisa_trie-1.1.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: simpful in ./anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->gsitk->moralstrength) (2.12.0)\n",
      "Requirement already satisfied: fst-pso in ./anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->gsitk->moralstrength) (1.8.1)\n",
      "Requirement already satisfied: miniful in ./anaconda3/lib/python3.11/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim->gsitk->moralstrength) (0.0.6)\n",
      "Downloading moralstrength-0.2.13-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m271.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gsitk-0.2.5-py3-none-any.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.7.4-cp311-cp311-macosx_11_0_arm64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m432.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m--:--\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl (488 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.4/488.4 kB\u001b[0m \u001b[31m645.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.3-cp311-cp311-macosx_11_0_arm64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.1/781.1 kB\u001b[0m \u001b[31m718.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m97.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading marisa_trie-1.1.1-cp311-cp311-macosx_11_0_arm64.whl (175 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pytreebank\n",
      "  Building wheel for pytreebank (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytreebank: filename=pytreebank-0.2.7-py3-none-any.whl size=37071 sha256=721eb5015dfe17341d6f3da45f8df7b0315fb3986cd46c83e10c58af62c19e12\n",
      "  Stored in directory: /Users/jiaojiao/Library/Caches/pip/wheels/d6/76/35/53861f6ddf9b2a448cb66ffc44231e794a8e636d0a027b9d39\n",
      "Successfully built pytreebank\n",
      "Installing collected packages: pytreebank, cymem, wasabi, typer, spacy-loggers, spacy-legacy, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy, gsitk, moralstrength\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 gsitk-0.2.5 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.1.1 moralstrength-0.2.13 murmurhash-1.0.10 preshed-3.0.9 pytreebank-0.2.7 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n",
      "Collecting cmfd\n",
      "  Downloading cmfd-0.2.1.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: cmfd\n",
      "  Building wheel for cmfd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cmfd: filename=cmfd-0.2.1-py3-none-any.whl size=4455 sha256=31aaaa462b024db08dd7d8e3fc70e812b9c35fe60eddefa58081de99ae570580\n",
      "  Stored in directory: /Users/jiaojiao/Library/Caches/pip/wheels/25/9c/05/c4a5c32081ae5fe42523e85ab07a13dff9701c0ec096956ea9\n",
      "Successfully built cmfd\n",
      "Installing collected packages: cmfd\n",
      "Successfully installed cmfd-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install moralstrength\n",
    "!pip install cmfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62ee592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files required by the Spacy language processing library (this is only required once)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in ./anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in ./anaconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./anaconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/4l/_lcd9phj5pz4r5t7ryzwbtzh0000gn/T/jieba.cache\n",
      "Loading model cost 0.254 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import moralstrength #英文道德词典\n",
    "from moralstrength import lexicon_use\n",
    "from moralstrength.moralstrength import estimate_morals\n",
    "import cmfd #中文道德词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59b2b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = pd.read_excel('/Users/jiaojiao/Downloads/text_analysis_twitter_sample.xlsx',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c47f2218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>time</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49374</td>\n",
       "      <td>890587249372524544</td>\n",
       "      <td>auctnr1</td>\n",
       "      <td>2017-07-27T10:58:41-04:00</td>\n",
       "      <td>https://www.twitter.com/Reuters/statuses/89058...</td>\n",
       "      <td>RT @Reuters MORE: Top U.S. general says, given...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83246</td>\n",
       "      <td>899354463055618048</td>\n",
       "      <td>SenatorTester</td>\n",
       "      <td>2017-08-20T15:36:27-04:00</td>\n",
       "      <td>https://www.twitter.com/SenatorTester/statuses...</td>\n",
       "      <td>T-minus 2 days until our first-ever Last Best ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100988</td>\n",
       "      <td>903272105738985472</td>\n",
       "      <td>KeithRothfus</td>\n",
       "      <td>2017-08-31T11:03:46-04:00</td>\n",
       "      <td>https://www.twitter.com/KeithRothfus/statuses/...</td>\n",
       "      <td>Please know that help is available. Visit http...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193395</td>\n",
       "      <td>921001114409021440</td>\n",
       "      <td>HASCRepublicans</td>\n",
       "      <td>2017-10-19T09:12:31-04:00</td>\n",
       "      <td>https://www.twitter.com/HASCRepublicans/status...</td>\n",
       "      <td>Literally flying the wings off the A-10 in fig...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12662</td>\n",
       "      <td>884911451449774080</td>\n",
       "      <td>SteveKnight25</td>\n",
       "      <td>2017-07-11T19:05:05-04:00</td>\n",
       "      <td>https://www.twitter.com/SteveKnight25/statuses...</td>\n",
       "      <td>Today the House unanimously passed my bill #HR...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  id      screen_name                       time  \\\n",
       "0   49374  890587249372524544          auctnr1  2017-07-27T10:58:41-04:00   \n",
       "1   83246  899354463055618048    SenatorTester  2017-08-20T15:36:27-04:00   \n",
       "2  100988  903272105738985472     KeithRothfus  2017-08-31T11:03:46-04:00   \n",
       "3  193395  921001114409021440  HASCRepublicans  2017-10-19T09:12:31-04:00   \n",
       "4   12662  884911451449774080    SteveKnight25  2017-07-11T19:05:05-04:00   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.twitter.com/Reuters/statuses/89058...   \n",
       "1  https://www.twitter.com/SenatorTester/statuses...   \n",
       "2  https://www.twitter.com/KeithRothfus/statuses/...   \n",
       "3  https://www.twitter.com/HASCRepublicans/status...   \n",
       "4  https://www.twitter.com/SteveKnight25/statuses...   \n",
       "\n",
       "                                                text              source  \n",
       "0  RT @Reuters MORE: Top U.S. general says, given...  Twitter for iPhone  \n",
       "1  T-minus 2 days until our first-ever Last Best ...  Twitter Web Client  \n",
       "2  Please know that help is available. Visit http...  Twitter Web Client  \n",
       "3  Literally flying the wings off the A-10 in fig...  Twitter Web Client  \n",
       "4  Today the House unanimously passed my bill #HR...  Twitter Web Client  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a71f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chn = pd.read_excel('/Users/jiaojiao/Downloads/text_analysis_ad.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dad88003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>商品名称</th>\n",
       "      <th>商品类别</th>\n",
       "      <th>出版年</th>\n",
       "      <th>广告文本</th>\n",
       "      <th>广告标题</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>五华牌香烟[May Blossom]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1932</td>\n",
       "      <td>兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...</td>\n",
       "      <td>五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5627</td>\n",
       "      <td>韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1918</td>\n",
       "      <td>讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...</td>\n",
       "      <td>韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13532</td>\n",
       "      <td>大炮台香烟[Three Castles Cigarettes]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1935</td>\n",
       "      <td>香味馥郁,不让名花 另有三炮台出售</td>\n",
       "      <td>大炮台香烟,\"香味馥郁 不让名花\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>婴孩自己药片[Baby's Own]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1930</td>\n",
       "      <td>差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...</td>\n",
       "      <td>婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3146</td>\n",
       "      <td>亚士北罗药片[Aspro]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1933</td>\n",
       "      <td>何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...</td>\n",
       "      <td>亚士北罗药片,\"妇女之腻友\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              商品名称  商品类别   出版年  \\\n",
       "0   1596                                五华牌香烟[May Blossom]  烟草制品  1932   \n",
       "1   5627  韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]    药品  1918   \n",
       "2  13532                   大炮台香烟[Three Castles Cigarettes]  烟草制品  1935   \n",
       "3   1133                                婴孩自己药片[Baby's Own]    药品  1930   \n",
       "4   3146                                     亚士北罗药片[Aspro]    药品  1933   \n",
       "\n",
       "                                                广告文本  \\\n",
       "0  兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...   \n",
       "1  讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...   \n",
       "2                                  香味馥郁,不让名花 另有三炮台出售   \n",
       "3  差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...   \n",
       "4  何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...   \n",
       "\n",
       "                              广告标题  \n",
       "0    五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"  \n",
       "1        韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'  \n",
       "2                大炮台香烟,\"香味馥郁 不让名花\"  \n",
       "3  婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"  \n",
       "4                   亚士北罗药片,\"妇女之腻友\"  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a1930",
   "metadata": {},
   "source": [
    "英文语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea84bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_use.select_version('latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbff9851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaojiao/anaconda3/lib/python3.11/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "#传入参数：数据表\n",
    "df_eng_morals = estimate_morals(df_eng['text'].tolist(),process = True)\n",
    "df_eng = pd.concat([df_eng,df_eng_morals],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44c9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>time</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>care</th>\n",
       "      <th>fairness</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>authority</th>\n",
       "      <th>purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49374</td>\n",
       "      <td>890587249372524544</td>\n",
       "      <td>auctnr1</td>\n",
       "      <td>2017-07-27T10:58:41-04:00</td>\n",
       "      <td>https://www.twitter.com/Reuters/statuses/89058...</td>\n",
       "      <td>RT @Reuters MORE: Top U.S. general says, given...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83246</td>\n",
       "      <td>899354463055618048</td>\n",
       "      <td>SenatorTester</td>\n",
       "      <td>2017-08-20T15:36:27-04:00</td>\n",
       "      <td>https://www.twitter.com/SenatorTester/statuses...</td>\n",
       "      <td>T-minus 2 days until our first-ever Last Best ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100988</td>\n",
       "      <td>903272105738985472</td>\n",
       "      <td>KeithRothfus</td>\n",
       "      <td>2017-08-31T11:03:46-04:00</td>\n",
       "      <td>https://www.twitter.com/KeithRothfus/statuses/...</td>\n",
       "      <td>Please know that help is available. Visit http...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193395</td>\n",
       "      <td>921001114409021440</td>\n",
       "      <td>HASCRepublicans</td>\n",
       "      <td>2017-10-19T09:12:31-04:00</td>\n",
       "      <td>https://www.twitter.com/HASCRepublicans/status...</td>\n",
       "      <td>Literally flying the wings off the A-10 in fig...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12662</td>\n",
       "      <td>884911451449774080</td>\n",
       "      <td>SteveKnight25</td>\n",
       "      <td>2017-07-11T19:05:05-04:00</td>\n",
       "      <td>https://www.twitter.com/SteveKnight25/statuses...</td>\n",
       "      <td>Today the House unanimously passed my bill #HR...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  id      screen_name                       time  \\\n",
       "0   49374  890587249372524544          auctnr1  2017-07-27T10:58:41-04:00   \n",
       "1   83246  899354463055618048    SenatorTester  2017-08-20T15:36:27-04:00   \n",
       "2  100988  903272105738985472     KeithRothfus  2017-08-31T11:03:46-04:00   \n",
       "3  193395  921001114409021440  HASCRepublicans  2017-10-19T09:12:31-04:00   \n",
       "4   12662  884911451449774080    SteveKnight25  2017-07-11T19:05:05-04:00   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.twitter.com/Reuters/statuses/89058...   \n",
       "1  https://www.twitter.com/SenatorTester/statuses...   \n",
       "2  https://www.twitter.com/KeithRothfus/statuses/...   \n",
       "3  https://www.twitter.com/HASCRepublicans/status...   \n",
       "4  https://www.twitter.com/SteveKnight25/statuses...   \n",
       "\n",
       "                                                text              source  \\\n",
       "0  RT @Reuters MORE: Top U.S. general says, given...  Twitter for iPhone   \n",
       "1  T-minus 2 days until our first-ever Last Best ...  Twitter Web Client   \n",
       "2  Please know that help is available. Visit http...  Twitter Web Client   \n",
       "3  Literally flying the wings off the A-10 in fig...  Twitter Web Client   \n",
       "4  Today the House unanimously passed my bill #HR...  Twitter Web Client   \n",
       "\n",
       "   care  fairness  loyalty  authority  purity  \n",
       "0   NaN       NaN      NaN        NaN     NaN  \n",
       "1   NaN       NaN      NaN        NaN     NaN  \n",
       "2   NaN       NaN      NaN        NaN     NaN  \n",
       "3   4.0       NaN      NaN        NaN     NaN  \n",
       "4   NaN       NaN      NaN        NaN     NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d9539",
   "metadata": {},
   "source": [
    "中文语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72310dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from URL.\n",
      "  chinese foundation\n",
      "0      同情       care\n",
      "1    一臂之力       care\n",
      "2    一见倾心       care\n",
      "3    三个代表       care\n",
      "4    上阵杀敌       care\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 尝试直接从 URL 读取\n",
    "try:\n",
    "    chn_moral = pd.read_csv('https://raw.githubusercontent.com/CivicTechLab/CMFD/main/cmfd_civictech.csv')\n",
    "    print(\"Data loaded successfully from URL.\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading data from URL:\", e)\n",
    "    # 如果 URL 读取失败，尝试读取本地文件\n",
    "    try:\n",
    "        chn_moral = pd.read_csv('cmfd_civictech.csv')\n",
    "        print(\"Data loaded successfully from local file.\")\n",
    "    except Exception as e_local:\n",
    "        print(\"Error loading data from local file:\", e_local)\n",
    "\n",
    "# 打印数据前几行\n",
    "print(chn_moral.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eda98817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chinese</th>\n",
       "      <th>foundation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>同情</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一臂之力</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一见倾心</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>三个代表</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>上阵杀敌</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>随和</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>雅正</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>雷打不动</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136</th>\n",
       "      <td>马马虎虎</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6137</th>\n",
       "      <td>骨节</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chinese foundation\n",
       "0         同情       care\n",
       "1       一臂之力       care\n",
       "2       一见倾心       care\n",
       "3       三个代表       care\n",
       "4       上阵杀敌       care\n",
       "...      ...        ...\n",
       "6133      随和    general\n",
       "6134      雅正    general\n",
       "6135    雷打不动    general\n",
       "6136    马马虎虎    general\n",
       "6137      骨节    general\n",
       "\n",
       "[6138 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chn_moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ef16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_dict = chn_moral.groupby('foundation')['chinese'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e4ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moral_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4811e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moral_quantity(text):\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        moral_word_total = 0\n",
    "        moral_word = {}\n",
    "        moral_num = {}\n",
    "\n",
    "        for key in moral_dict.keys():\n",
    "            moral_word[key] = []\n",
    "        for word in jieba.cut(text):\n",
    "            for key in moral_dict.keys():\n",
    "                if word in moral_dict[key]:\n",
    "                    moral_word[key].append(word)\n",
    "\n",
    "        for key in moral_word.keys():\n",
    "            moral_word_total += len(moral_word[key])\n",
    "        if moral_word_total == 0:\n",
    "            return None\n",
    "\n",
    "        for key in moral_word.keys():\n",
    "            moral_num[key] = len(moral_word[key]) / moral_word_total\n",
    "\n",
    "    return moral_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "421191a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = \"\"\"在一个古老的王国里，有一位年轻的王子，名叫艾伦。他爱上了王国中一个普通的女孩，名叫艾丽丝。然而，王子的父亲，即国王，却不同意这段感情，因为他认为艾丽丝的出身不够高贵，不适合成为王室的一员。\n",
    "\n",
    "王子面临着艰难的选择，他可以违抗父王的意愿和艾丽丝在一起，但这意味着他要放弃王位和王国的责任。另一方面，他也可以遵从父王的意愿，选择一个地位高贵但他并不爱的女子，这样可以继续承担王国的责任。\n",
    "\n",
    "在经过深思熟虑后，王子决定选择违抗父王的意愿，选择与艾丽丝在一起。他认为爱情比地位和财富更重要，而且他也相信只有在爱情的支持下，他才能成为一个真正的幸福的国王。\n",
    "\n",
    "尽管他的决定引起了一些争议和反对，但王子坚持了自己的选择，并与艾丽丝结为夫妻。他们的爱情和幸福成为了王国中的典范，人们开始理解和尊重不同阶层之间的爱情，认识到爱情是超越地位和财富的。\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d3beac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'altr': 0.0,\n",
       " 'auth': 0.5161290322580645,\n",
       " 'care': 0.06451612903225806,\n",
       " 'dili': 0.0,\n",
       " 'fair': 0.0,\n",
       " 'general': 0.06451612903225806,\n",
       " 'libe': 0.0,\n",
       " 'loya': 0.12903225806451613,\n",
       " 'mode': 0.03225806451612903,\n",
       " 'resi': 0.03225806451612903,\n",
       " 'sanc': 0.16129032258064516,\n",
       " 'wast': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moral_quantity(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d01a4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>商品名称</th>\n",
       "      <th>商品类别</th>\n",
       "      <th>出版年</th>\n",
       "      <th>广告文本</th>\n",
       "      <th>广告标题</th>\n",
       "      <th>chn_moral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>五华牌香烟[May Blossom]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1932</td>\n",
       "      <td>兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...</td>\n",
       "      <td>五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5627</td>\n",
       "      <td>韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1918</td>\n",
       "      <td>讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...</td>\n",
       "      <td>韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'</td>\n",
       "      <td>{'altr': 0.0, 'auth': 0.25, 'care': 0.25, 'dil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13532</td>\n",
       "      <td>大炮台香烟[Three Castles Cigarettes]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1935</td>\n",
       "      <td>香味馥郁,不让名花 另有三炮台出售</td>\n",
       "      <td>大炮台香烟,\"香味馥郁 不让名花\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>婴孩自己药片[Baby's Own]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1930</td>\n",
       "      <td>差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...</td>\n",
       "      <td>婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"</td>\n",
       "      <td>{'altr': 0.0, 'auth': 0.2, 'care': 0.2, 'dili'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3146</td>\n",
       "      <td>亚士北罗药片[Aspro]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1933</td>\n",
       "      <td>何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...</td>\n",
       "      <td>亚士北罗药片,\"妇女之腻友\"</td>\n",
       "      <td>{'altr': 0.0, 'auth': 0.16666666666666666, 'ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              商品名称  商品类别   出版年  \\\n",
       "0   1596                                五华牌香烟[May Blossom]  烟草制品  1932   \n",
       "1   5627  韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]    药品  1918   \n",
       "2  13532                   大炮台香烟[Three Castles Cigarettes]  烟草制品  1935   \n",
       "3   1133                                婴孩自己药片[Baby's Own]    药品  1930   \n",
       "4   3146                                     亚士北罗药片[Aspro]    药品  1933   \n",
       "\n",
       "                                                广告文本  \\\n",
       "0  兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...   \n",
       "1  讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...   \n",
       "2                                  香味馥郁,不让名花 另有三炮台出售   \n",
       "3  差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...   \n",
       "4  何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...   \n",
       "\n",
       "                              广告标题  \\\n",
       "0    五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"   \n",
       "1        韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'   \n",
       "2                大炮台香烟,\"香味馥郁 不让名花\"   \n",
       "3  婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"   \n",
       "4                   亚士北罗药片,\"妇女之腻友\"   \n",
       "\n",
       "                                           chn_moral  \n",
       "0                                               None  \n",
       "1  {'altr': 0.0, 'auth': 0.25, 'care': 0.25, 'dil...  \n",
       "2                                               None  \n",
       "3  {'altr': 0.0, 'auth': 0.2, 'care': 0.2, 'dili'...  \n",
       "4  {'altr': 0.0, 'auth': 0.16666666666666666, 'ca...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chn['chn_moral'] = df_chn['广告文本'].apply(moral_quantity)\n",
    "df_chn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04b219a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>商品名称</th>\n",
       "      <th>商品类别</th>\n",
       "      <th>出版年</th>\n",
       "      <th>广告文本</th>\n",
       "      <th>广告标题</th>\n",
       "      <th>chn_moral</th>\n",
       "      <th>altr</th>\n",
       "      <th>auth</th>\n",
       "      <th>care</th>\n",
       "      <th>dili</th>\n",
       "      <th>fair</th>\n",
       "      <th>general</th>\n",
       "      <th>libe</th>\n",
       "      <th>loya</th>\n",
       "      <th>mode</th>\n",
       "      <th>resi</th>\n",
       "      <th>sanc</th>\n",
       "      <th>wast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>五华牌香烟[May Blossom]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1932</td>\n",
       "      <td>兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...</td>\n",
       "      <td>五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5627</td>\n",
       "      <td>韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1918</td>\n",
       "      <td>讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...</td>\n",
       "      <td>韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'</td>\n",
       "      <td>{'altr': 0.0, 'auth': 0.25, 'care': 0.25, 'dil...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13532</td>\n",
       "      <td>大炮台香烟[Three Castles Cigarettes]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1935</td>\n",
       "      <td>香味馥郁,不让名花 另有三炮台出售</td>\n",
       "      <td>大炮台香烟,\"香味馥郁 不让名花\"</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>婴孩自己药片[Baby's Own]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1930</td>\n",
       "      <td>差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...</td>\n",
       "      <td>婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"</td>\n",
       "      <td>{'altr': 0.0, 'auth': 0.2, 'care': 0.2, 'dili'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3146</td>\n",
       "      <td>亚士北罗药片[Aspro]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1933</td>\n",
       "      <td>何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...</td>\n",
       "      <td>亚士北罗药片,\"妇女之腻友\"</td>\n",
       "      <td>{'altr': 0.0, 'auth': 0.16666666666666666, 'ca...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              商品名称  商品类别   出版年  \\\n",
       "0   1596                                五华牌香烟[May Blossom]  烟草制品  1932   \n",
       "1   5627  韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]    药品  1918   \n",
       "2  13532                   大炮台香烟[Three Castles Cigarettes]  烟草制品  1935   \n",
       "3   1133                                婴孩自己药片[Baby's Own]    药品  1930   \n",
       "4   3146                                     亚士北罗药片[Aspro]    药品  1933   \n",
       "\n",
       "                                                广告文本  \\\n",
       "0  兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...   \n",
       "1  讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...   \n",
       "2                                  香味馥郁,不让名花 另有三炮台出售   \n",
       "3  差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...   \n",
       "4  何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...   \n",
       "\n",
       "                              广告标题  \\\n",
       "0    五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"   \n",
       "1        韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'   \n",
       "2                大炮台香烟,\"香味馥郁 不让名花\"   \n",
       "3  婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"   \n",
       "4                   亚士北罗药片,\"妇女之腻友\"   \n",
       "\n",
       "                                           chn_moral  altr      auth  \\\n",
       "0                                               None   NaN       NaN   \n",
       "1  {'altr': 0.0, 'auth': 0.25, 'care': 0.25, 'dil...   0.0  0.250000   \n",
       "2                                               None   NaN       NaN   \n",
       "3  {'altr': 0.0, 'auth': 0.2, 'care': 0.2, 'dili'...   0.0  0.200000   \n",
       "4  {'altr': 0.0, 'auth': 0.16666666666666666, 'ca...   0.0  0.166667   \n",
       "\n",
       "       care  dili      fair  general  libe      loya  mode  resi      sanc  \\\n",
       "0       NaN   NaN       NaN      NaN   NaN       NaN   NaN   NaN       NaN   \n",
       "1  0.250000   0.0  0.000000      0.0   0.0  0.000000   0.0   0.0  0.500000   \n",
       "2       NaN   NaN       NaN      NaN   NaN       NaN   NaN   NaN       NaN   \n",
       "3  0.200000   0.0  0.000000      0.0   0.0  0.200000   0.2   0.0  0.200000   \n",
       "4  0.166667   0.0  0.055556      0.0   0.0  0.388889   0.0   0.0  0.222222   \n",
       "\n",
       "   wast  \n",
       "0   NaN  \n",
       "1   0.0  \n",
       "2   NaN  \n",
       "3   0.0  \n",
       "4   0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chn_moral_df = pd.DataFrame(columns=['altr', 'auth', 'care', 'dili', 'fair', 'general', 'libe', 'loya', 'mode', 'resi', 'sanc', 'wast'])\n",
    "\n",
    "for dc in df_chn.index:\n",
    "    if df_chn['chn_moral'][dc] == None:\n",
    "        chn_moral_df.loc[len(chn_moral_df.index)] = [None] * 12\n",
    "    else:\n",
    "        chn_moral_df.loc[len(chn_moral_df.index)] = list(df_chn['chn_moral'][dc].values())\n",
    "        \n",
    "df_chn = pd.concat([df_chn, chn_moral_df], axis=1)\n",
    "        \n",
    "df_chn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef4b367a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', '商品名称', '商品类别', '出版年', '广告文本', '广告标题', 'chn_moral', 'altr',\n",
       "       'auth', 'care', 'dili', 'fair', 'general', 'libe', 'loya', 'mode',\n",
       "       'resi', 'sanc', 'wast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c06854",
   "metadata": {},
   "source": [
    "## 情感词典"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43a1e8",
   "metadata": {},
   "source": [
    "情感词典（Sentiment Lexicon）是一种用于文本分析的工具，它包含了一组词汇及其对应的情感倾向（通常包括正面、负面或中性情感）。情感词典在自然语言处理（NLP）和情感分析（Sentiment Analysis）中广泛使用，用于判断文本或单词的情感极性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f80fe",
   "metadata": {},
   "source": [
    "1. 组成与结构：词汇：包括单词、短语或词组。\n",
    "\n",
    "        情感标签：每个词汇都附有一个或多个情感标签。这些标签可以是：\n",
    "\n",
    "        情感极性：正面（positive）、负面（negative）、中性（neutral）。\n",
    "\n",
    "           情感类别：如愤怒（anger）、快乐（joy）、悲伤（sadness）、惊讶（surprise）、信任（trust）等。\n",
    "    \n",
    "           情感强度：一些情感词典还包含每个词汇情感的强度或权重。\n",
    "    \n",
    "\n",
    "2. 常见的情感词典：\n",
    "\n",
    "        NRC情感词典（NRC Emotion Lexicon）：包含多个情感类别，如愤怒、期待、厌恶、恐惧、快乐、悲伤、惊讶和信任。\n",
    "\n",
    "        SentiWordNet：为每个单词分配正面、负面和中性评分。\n",
    "\n",
    "        AFINN：基于词汇的情感极性评分，分值从-5（非常负面）到+5（非常正面）。\n",
    "\n",
    "        VADER（Valence Aware Dictionary and sEntiment Reasoner）：专门用于社交媒体文本的情感分析。\n",
    "\n",
    "\n",
    "3. 工作原理\n",
    "\n",
    "        文本预处理：将文本分词并进行必要的清洗，如去除停用词、标点符号等。\n",
    "\n",
    "        词汇匹配：将预处理后的词汇与情感词典中的词汇进行匹配。\n",
    " \n",
    "        情感评分：根据匹配到的词汇情感标签，计算文本的整体情感得分或分类。\n",
    "\n",
    "        结果输出：输出文本的情感分析结果，可以是情感极性、情感类别或具体的情感评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ce88485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     # 数据表\n",
    "import jieba     # 中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54d55fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = pd.read_excel('/Users/jiaojiao/Downloads/text_analysis_twitter_sample.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df260078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>time</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49374</td>\n",
       "      <td>890587249372524544</td>\n",
       "      <td>auctnr1</td>\n",
       "      <td>2017-07-27T10:58:41-04:00</td>\n",
       "      <td>https://www.twitter.com/Reuters/statuses/89058...</td>\n",
       "      <td>RT @Reuters MORE: Top U.S. general says, given...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83246</td>\n",
       "      <td>899354463055618048</td>\n",
       "      <td>SenatorTester</td>\n",
       "      <td>2017-08-20T15:36:27-04:00</td>\n",
       "      <td>https://www.twitter.com/SenatorTester/statuses...</td>\n",
       "      <td>T-minus 2 days until our first-ever Last Best ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100988</td>\n",
       "      <td>903272105738985472</td>\n",
       "      <td>KeithRothfus</td>\n",
       "      <td>2017-08-31T11:03:46-04:00</td>\n",
       "      <td>https://www.twitter.com/KeithRothfus/statuses/...</td>\n",
       "      <td>Please know that help is available. Visit http...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193395</td>\n",
       "      <td>921001114409021440</td>\n",
       "      <td>HASCRepublicans</td>\n",
       "      <td>2017-10-19T09:12:31-04:00</td>\n",
       "      <td>https://www.twitter.com/HASCRepublicans/status...</td>\n",
       "      <td>Literally flying the wings off the A-10 in fig...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12662</td>\n",
       "      <td>884911451449774080</td>\n",
       "      <td>SteveKnight25</td>\n",
       "      <td>2017-07-11T19:05:05-04:00</td>\n",
       "      <td>https://www.twitter.com/SteveKnight25/statuses...</td>\n",
       "      <td>Today the House unanimously passed my bill #HR...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  id      screen_name                       time  \\\n",
       "0   49374  890587249372524544          auctnr1  2017-07-27T10:58:41-04:00   \n",
       "1   83246  899354463055618048    SenatorTester  2017-08-20T15:36:27-04:00   \n",
       "2  100988  903272105738985472     KeithRothfus  2017-08-31T11:03:46-04:00   \n",
       "3  193395  921001114409021440  HASCRepublicans  2017-10-19T09:12:31-04:00   \n",
       "4   12662  884911451449774080    SteveKnight25  2017-07-11T19:05:05-04:00   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.twitter.com/Reuters/statuses/89058...   \n",
       "1  https://www.twitter.com/SenatorTester/statuses...   \n",
       "2  https://www.twitter.com/KeithRothfus/statuses/...   \n",
       "3  https://www.twitter.com/HASCRepublicans/status...   \n",
       "4  https://www.twitter.com/SteveKnight25/statuses...   \n",
       "\n",
       "                                                text              source  \n",
       "0  RT @Reuters MORE: Top U.S. general says, given...  Twitter for iPhone  \n",
       "1  T-minus 2 days until our first-ever Last Best ...  Twitter Web Client  \n",
       "2  Please know that help is available. Visit http...  Twitter Web Client  \n",
       "3  Literally flying the wings off the A-10 in fig...  Twitter Web Client  \n",
       "4  Today the House unanimously passed my bill #HR...  Twitter Web Client  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b977fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_chn = pd.read_excel('/Users/jiaojiao/Downloads/text_analysis_ad.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2098f5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>商品名称</th>\n",
       "      <th>商品类别</th>\n",
       "      <th>出版年</th>\n",
       "      <th>广告文本</th>\n",
       "      <th>广告标题</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>五华牌香烟[May Blossom]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1932</td>\n",
       "      <td>兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...</td>\n",
       "      <td>五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5627</td>\n",
       "      <td>韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1918</td>\n",
       "      <td>讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...</td>\n",
       "      <td>韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13532</td>\n",
       "      <td>大炮台香烟[Three Castles Cigarettes]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1935</td>\n",
       "      <td>香味馥郁,不让名花 另有三炮台出售</td>\n",
       "      <td>大炮台香烟,\"香味馥郁 不让名花\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>婴孩自己药片[Baby's Own]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1930</td>\n",
       "      <td>差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...</td>\n",
       "      <td>婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3146</td>\n",
       "      <td>亚士北罗药片[Aspro]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1933</td>\n",
       "      <td>何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...</td>\n",
       "      <td>亚士北罗药片,\"妇女之腻友\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              商品名称  商品类别   出版年  \\\n",
       "0   1596                                五华牌香烟[May Blossom]  烟草制品  1932   \n",
       "1   5627  韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]    药品  1918   \n",
       "2  13532                   大炮台香烟[Three Castles Cigarettes]  烟草制品  1935   \n",
       "3   1133                                婴孩自己药片[Baby's Own]    药品  1930   \n",
       "4   3146                                     亚士北罗药片[Aspro]    药品  1933   \n",
       "\n",
       "                                                广告文本  \\\n",
       "0  兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...   \n",
       "1  讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...   \n",
       "2                                  香味馥郁,不让名花 另有三炮台出售   \n",
       "3  差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...   \n",
       "4  何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...   \n",
       "\n",
       "                              广告标题  \n",
       "0    五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"  \n",
       "1        韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'  \n",
       "2                大炮台香烟,\"香味馥郁 不让名花\"  \n",
       "3  婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"  \n",
       "4                   亚士北罗药片,\"妇女之腻友\"  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2120842",
   "metadata": {},
   "source": [
    "### NRC情感词典（NRC Emotion Lexicon）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8844a",
   "metadata": {},
   "source": [
    "#### 英文语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a1fed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaojiao/anaconda3/lib/python3.11/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engword</th>\n",
       "      <th>Chnword</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anticipation</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aback</td>\n",
       "      <td>吓了一跳</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>算盘</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>放弃</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>弃</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>放弃</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Engword Chnword  Positive  Negative  Anger  Anticipation  Disgust  \\\n",
       "0        aback    吓了一跳         0         0      0             0        0   \n",
       "1       abacus      算盘         0         0      0             0        0   \n",
       "2      abandon      放弃         0         1      0             0        0   \n",
       "3    abandoned       弃         0         1      1             0        0   \n",
       "4  abandonment      放弃         0         1      1             0        0   \n",
       "\n",
       "   Fear  Joy  Sadness  Surprise  Trust  \n",
       "0     0    0        0         0      0  \n",
       "1     0    0        0         0      1  \n",
       "2     1    0        1         0      0  \n",
       "3     1    0        1         0      0  \n",
       "4     1    0        1         1      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrc = pd.read_excel('/Users/jiaojiao/Downloads/NRC-Emotion-Lexicon.xlsx', usecols='A, F, AP:AY')\n",
    "nrc = nrc.rename(columns={'English Word':'Engword', 'Chinese (simplified) Translation (Google Translate)':'Chnword'})\n",
    "nrc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b59d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive, Negative, Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, Trust = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for idx, row in nrc.iterrows():\n",
    "    if row['Positive'] == 1:\n",
    "        Positive.append(row['Engword'])\n",
    "    if row['Negative'] == 1:\n",
    "        Negative.append(row['Engword'])\n",
    "    if row['Anger'] == 1:\n",
    "        Anger.append(row['Engword'])\n",
    "    if row['Anticipation'] == 1:\n",
    "        Anticipation.append(row['Engword'])\n",
    "    if row['Disgust'] == 1:\n",
    "        Disgust.append(row['Engword'])\n",
    "    if row['Fear'] == 1:\n",
    "        Fear.append(row['Engword'])\n",
    "    if row['Joy'] == 1:\n",
    "        Joy.append(row['Engword'])\n",
    "    if row['Sadness'] == 1:\n",
    "        Sadness.append(row['Engword'])\n",
    "    if row['Surprise'] == 1:\n",
    "        Surprise.append(row['Engword'])\n",
    "    if row['Trust'] == 1:\n",
    "        Trust.append(row['Engword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02306af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_nrc</th>\n",
       "      <th>positive_nrc</th>\n",
       "      <th>negative_nrc</th>\n",
       "      <th>anger_nrc</th>\n",
       "      <th>anticipation_nrc</th>\n",
       "      <th>disgust_nrc</th>\n",
       "      <th>fear_nrc</th>\n",
       "      <th>joy_nrc</th>\n",
       "      <th>sadness_nrc</th>\n",
       "      <th>surprise_nrc</th>\n",
       "      <th>trust_nrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  length_nrc positive_nrc negative_nrc anger_nrc anticipation_nrc disgust_nrc  \\\n",
       "0         22            2            0         0                1           0   \n",
       "1         18            1            0         0                1           0   \n",
       "2         16            1            0         0                0           0   \n",
       "3         22            1            1         1                0           0   \n",
       "4         20            0            1         1                0           1   \n",
       "\n",
       "  fear_nrc joy_nrc sadness_nrc surprise_nrc trust_nrc  \n",
       "0        0       0           0            0         2  \n",
       "1        0       1           0            1         1  \n",
       "2        0       0           0            0         0  \n",
       "3        2       0           0            0         0  \n",
       "4        1       0           1            1         1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_nrc_eng = pd.DataFrame(columns=['length_nrc', 'positive_nrc', 'negative_nrc',\n",
    "                                    'anger_nrc', 'anticipation_nrc', 'disgust_nrc', 'fear_nrc',\n",
    "                                    'joy_nrc', 'sadness_nrc', 'surprise_nrc', 'trust_nrc'])\n",
    "\n",
    "for de in df_eng.index:\n",
    "    positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, trust = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    text = df_eng['text'][de].lower()\n",
    "    wordlist = text.split()\n",
    "    wordset = set(wordlist)\n",
    "    wordfreq = []\n",
    "    \n",
    "    for word in wordset:\n",
    "        freq = wordlist.count(word)\n",
    "        if word in Positive:\n",
    "            positive += freq\n",
    "        if word in Negative:\n",
    "            negative += freq\n",
    "        if word in Anger:\n",
    "            anger += freq\n",
    "        if word in Anticipation:\n",
    "            anticipation += freq\n",
    "        if word in Disgust:\n",
    "            disgust += freq\n",
    "        if word in Fear:\n",
    "            fear += freq\n",
    "        if word in Joy:\n",
    "            joy += freq\n",
    "        if word in Sadness:\n",
    "            sadness += freq\n",
    "        if word in Surprise:\n",
    "            surprise += freq\n",
    "        if word in Trust:\n",
    "            trust += freq\n",
    "            \n",
    "    emotion_info = {\n",
    "        'length_nrc': len(wordlist),\n",
    "        'positive_nrc': positive,\n",
    "        'negative_nrc': negative,\n",
    "        'anger_nrc': anger,\n",
    "        'anticipation_nrc': anticipation,\n",
    "        'disgust_nrc': disgust,\n",
    "        'fear_nrc': fear,\n",
    "        'joy_nrc': joy,\n",
    "        'sadness_nrc': sadness,\n",
    "        'surprise_nrc': surprise,\n",
    "        'trust_nrc': trust\n",
    "    }\n",
    "    \n",
    "    emo_info = pd.DataFrame([emotion_info])\n",
    "    emo_nrc_eng = pd.concat([emo_nrc_eng, emo_info], ignore_index=True)\n",
    "    \n",
    "emo_nrc_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59e550fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>time</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>length_nrc</th>\n",
       "      <th>positive_nrc</th>\n",
       "      <th>negative_nrc</th>\n",
       "      <th>anger_nrc</th>\n",
       "      <th>anticipation_nrc</th>\n",
       "      <th>disgust_nrc</th>\n",
       "      <th>fear_nrc</th>\n",
       "      <th>joy_nrc</th>\n",
       "      <th>sadness_nrc</th>\n",
       "      <th>surprise_nrc</th>\n",
       "      <th>trust_nrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49374</td>\n",
       "      <td>890587249372524544</td>\n",
       "      <td>auctnr1</td>\n",
       "      <td>2017-07-27T10:58:41-04:00</td>\n",
       "      <td>https://www.twitter.com/Reuters/statuses/89058...</td>\n",
       "      <td>RT @Reuters MORE: Top U.S. general says, given...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83246</td>\n",
       "      <td>899354463055618048</td>\n",
       "      <td>SenatorTester</td>\n",
       "      <td>2017-08-20T15:36:27-04:00</td>\n",
       "      <td>https://www.twitter.com/SenatorTester/statuses...</td>\n",
       "      <td>T-minus 2 days until our first-ever Last Best ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100988</td>\n",
       "      <td>903272105738985472</td>\n",
       "      <td>KeithRothfus</td>\n",
       "      <td>2017-08-31T11:03:46-04:00</td>\n",
       "      <td>https://www.twitter.com/KeithRothfus/statuses/...</td>\n",
       "      <td>Please know that help is available. Visit http...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193395</td>\n",
       "      <td>921001114409021440</td>\n",
       "      <td>HASCRepublicans</td>\n",
       "      <td>2017-10-19T09:12:31-04:00</td>\n",
       "      <td>https://www.twitter.com/HASCRepublicans/status...</td>\n",
       "      <td>Literally flying the wings off the A-10 in fig...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12662</td>\n",
       "      <td>884911451449774080</td>\n",
       "      <td>SteveKnight25</td>\n",
       "      <td>2017-07-11T19:05:05-04:00</td>\n",
       "      <td>https://www.twitter.com/SteveKnight25/statuses...</td>\n",
       "      <td>Today the House unanimously passed my bill #HR...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  id      screen_name                       time  \\\n",
       "0   49374  890587249372524544          auctnr1  2017-07-27T10:58:41-04:00   \n",
       "1   83246  899354463055618048    SenatorTester  2017-08-20T15:36:27-04:00   \n",
       "2  100988  903272105738985472     KeithRothfus  2017-08-31T11:03:46-04:00   \n",
       "3  193395  921001114409021440  HASCRepublicans  2017-10-19T09:12:31-04:00   \n",
       "4   12662  884911451449774080    SteveKnight25  2017-07-11T19:05:05-04:00   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.twitter.com/Reuters/statuses/89058...   \n",
       "1  https://www.twitter.com/SenatorTester/statuses...   \n",
       "2  https://www.twitter.com/KeithRothfus/statuses/...   \n",
       "3  https://www.twitter.com/HASCRepublicans/status...   \n",
       "4  https://www.twitter.com/SteveKnight25/statuses...   \n",
       "\n",
       "                                                text              source  \\\n",
       "0  RT @Reuters MORE: Top U.S. general says, given...  Twitter for iPhone   \n",
       "1  T-minus 2 days until our first-ever Last Best ...  Twitter Web Client   \n",
       "2  Please know that help is available. Visit http...  Twitter Web Client   \n",
       "3  Literally flying the wings off the A-10 in fig...  Twitter Web Client   \n",
       "4  Today the House unanimously passed my bill #HR...  Twitter Web Client   \n",
       "\n",
       "  length_nrc positive_nrc negative_nrc anger_nrc anticipation_nrc disgust_nrc  \\\n",
       "0         22            2            0         0                1           0   \n",
       "1         18            1            0         0                1           0   \n",
       "2         16            1            0         0                0           0   \n",
       "3         22            1            1         1                0           0   \n",
       "4         20            0            1         1                0           1   \n",
       "\n",
       "  fear_nrc joy_nrc sadness_nrc surprise_nrc trust_nrc  \n",
       "0        0       0           0            0         2  \n",
       "1        0       1           0            1         1  \n",
       "2        0       0           0            0         0  \n",
       "3        2       0           0            0         0  \n",
       "4        1       0           1            1         1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng = pd.concat([df_eng, emo_nrc_eng], axis=1)\n",
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3715010",
   "metadata": {},
   "source": [
    "#### 中文语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a95e9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive, Negative, Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, Trust = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for idx, row in nrc.iterrows():\n",
    "    if row['Positive'] == 1:\n",
    "        Positive.append(row['Chnword'])\n",
    "    if row['Negative'] == 1:\n",
    "        Negative.append(row['Chnword'])\n",
    "    if row['Anger'] == 1:\n",
    "        Anger.append(row['Chnword'])\n",
    "    if row['Anticipation'] == 1:\n",
    "        Anticipation.append(row['Chnword'])\n",
    "    if row['Disgust'] == 1:\n",
    "        Disgust.append(row['Chnword'])\n",
    "    if row['Fear'] == 1:\n",
    "        Fear.append(row['Chnword'])\n",
    "    if row['Joy'] == 1:\n",
    "        Joy.append(row['Chnword'])\n",
    "    if row['Sadness'] == 1:\n",
    "        Sadness.append(row['Chnword'])\n",
    "    if row['Surprise'] == 1:\n",
    "        Surprise.append(row['Chnword'])\n",
    "    if row['Trust'] == 1:\n",
    "        Trust.append(row['Chnword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a28a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/4l/_lcd9phj5pz4r5t7ryzwbtzh0000gn/T/jieba.cache\n",
      "Loading model cost 0.266 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_nrc</th>\n",
       "      <th>positive_nrc</th>\n",
       "      <th>negative_nrc</th>\n",
       "      <th>anger_nrc</th>\n",
       "      <th>anticipation_nrc</th>\n",
       "      <th>disgust_nrc</th>\n",
       "      <th>fear_nrc</th>\n",
       "      <th>joy_nrc</th>\n",
       "      <th>sadness_nrc</th>\n",
       "      <th>surprise_nrc</th>\n",
       "      <th>trust_nrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  length_nrc positive_nrc negative_nrc anger_nrc anticipation_nrc disgust_nrc  \\\n",
       "0         30            1            2         0                0           0   \n",
       "1        129            7           11         1                0           8   \n",
       "2         11            0            0         0                0           0   \n",
       "3        155            7            7         2                3           4   \n",
       "4        433           19           14         4                9           4   \n",
       "\n",
       "  fear_nrc joy_nrc sadness_nrc surprise_nrc trust_nrc  \n",
       "0        0       0           0            0         1  \n",
       "1        2       0           3            0         4  \n",
       "2        0       0           0            0         0  \n",
       "3        3       2           1            0         4  \n",
       "4        4       9           8            4        13  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_nrc_chn = pd.DataFrame(columns=['length_nrc', 'positive_nrc', 'negative_nrc',\n",
    "                                    'anger_nrc', 'anticipation_nrc', 'disgust_nrc', 'fear_nrc',\n",
    "                                    'joy_nrc', 'sadness_nrc', 'surprise_nrc', 'trust_nrc'])\n",
    "\n",
    "for dc in df_chn.index:\n",
    "    positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, trust = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    wordlist = list(jieba.cut(df_chn['广告文本'][dc]))\n",
    "    wordset = set(wordlist)\n",
    "    wordfreq = []\n",
    "    \n",
    "    for word in wordset:\n",
    "        freq = wordlist.count(word)\n",
    "        if word in Positive:\n",
    "            positive += freq\n",
    "        if word in Negative:\n",
    "            negative += freq\n",
    "        if word in Anger:\n",
    "            anger += freq\n",
    "        if word in Anticipation:\n",
    "            anticipation += freq\n",
    "        if word in Disgust:\n",
    "            disgust += freq\n",
    "        if word in Fear:\n",
    "            fear += freq\n",
    "        if word in Joy:\n",
    "            joy += freq\n",
    "        if word in Sadness:\n",
    "            sadness += freq\n",
    "        if word in Surprise:\n",
    "            surprise += freq\n",
    "        if word in Trust:\n",
    "            trust += freq\n",
    "            \n",
    "    emotion_info = {\n",
    "        'length_nrc': len(wordlist),\n",
    "        'positive_nrc': positive,\n",
    "        'negative_nrc': negative,\n",
    "        'anger_nrc': anger,\n",
    "        'anticipation_nrc': anticipation,\n",
    "        'disgust_nrc': disgust,\n",
    "        'fear_nrc': fear,\n",
    "        'joy_nrc': joy,\n",
    "        'sadness_nrc': sadness,\n",
    "        'surprise_nrc': surprise,\n",
    "        'trust_nrc': trust\n",
    "    }\n",
    "    \n",
    "    emo_info = pd.DataFrame([emotion_info])\n",
    "    emo_nrc_chn = pd.concat([emo_nrc_chn, emo_info], ignore_index=True)\n",
    "\n",
    "emo_nrc_chn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83457ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>商品名称</th>\n",
       "      <th>商品类别</th>\n",
       "      <th>出版年</th>\n",
       "      <th>广告文本</th>\n",
       "      <th>广告标题</th>\n",
       "      <th>length_nrc</th>\n",
       "      <th>positive_nrc</th>\n",
       "      <th>negative_nrc</th>\n",
       "      <th>anger_nrc</th>\n",
       "      <th>anticipation_nrc</th>\n",
       "      <th>disgust_nrc</th>\n",
       "      <th>fear_nrc</th>\n",
       "      <th>joy_nrc</th>\n",
       "      <th>sadness_nrc</th>\n",
       "      <th>surprise_nrc</th>\n",
       "      <th>trust_nrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>五华牌香烟[May Blossom]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1932</td>\n",
       "      <td>兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...</td>\n",
       "      <td>五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5627</td>\n",
       "      <td>韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1918</td>\n",
       "      <td>讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...</td>\n",
       "      <td>韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'</td>\n",
       "      <td>129</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13532</td>\n",
       "      <td>大炮台香烟[Three Castles Cigarettes]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1935</td>\n",
       "      <td>香味馥郁,不让名花 另有三炮台出售</td>\n",
       "      <td>大炮台香烟,\"香味馥郁 不让名花\"</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>婴孩自己药片[Baby's Own]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1930</td>\n",
       "      <td>差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...</td>\n",
       "      <td>婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3146</td>\n",
       "      <td>亚士北罗药片[Aspro]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1933</td>\n",
       "      <td>何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...</td>\n",
       "      <td>亚士北罗药片,\"妇女之腻友\"</td>\n",
       "      <td>433</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              商品名称  商品类别   出版年  \\\n",
       "0   1596                                五华牌香烟[May Blossom]  烟草制品  1932   \n",
       "1   5627  韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]    药品  1918   \n",
       "2  13532                   大炮台香烟[Three Castles Cigarettes]  烟草制品  1935   \n",
       "3   1133                                婴孩自己药片[Baby's Own]    药品  1930   \n",
       "4   3146                                     亚士北罗药片[Aspro]    药品  1933   \n",
       "\n",
       "                                                广告文本  \\\n",
       "0  兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...   \n",
       "1  讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...   \n",
       "2                                  香味馥郁,不让名花 另有三炮台出售   \n",
       "3  差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...   \n",
       "4  何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...   \n",
       "\n",
       "                              广告标题 length_nrc positive_nrc negative_nrc  \\\n",
       "0    五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"         30            1            2   \n",
       "1        韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'        129            7           11   \n",
       "2                大炮台香烟,\"香味馥郁 不让名花\"         11            0            0   \n",
       "3  婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"        155            7            7   \n",
       "4                   亚士北罗药片,\"妇女之腻友\"        433           19           14   \n",
       "\n",
       "  anger_nrc anticipation_nrc disgust_nrc fear_nrc joy_nrc sadness_nrc  \\\n",
       "0         0                0           0        0       0           0   \n",
       "1         1                0           8        2       0           3   \n",
       "2         0                0           0        0       0           0   \n",
       "3         2                3           4        3       2           1   \n",
       "4         4                9           4        4       9           8   \n",
       "\n",
       "  surprise_nrc trust_nrc  \n",
       "0            0         1  \n",
       "1            0         4  \n",
       "2            0         0  \n",
       "3            0         4  \n",
       "4            4        13  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chn = pd.concat([df_chn, emo_nrc_chn], axis=1)\n",
    "df_chn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4133257",
   "metadata": {},
   "source": [
    "### 大连理工大学情感词典（DLUT Emotion Lexicon）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd142255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>词语</th>\n",
       "      <th>词性种类</th>\n",
       "      <th>情感分类</th>\n",
       "      <th>强度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>脏乱</td>\n",
       "      <td>adj</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>糟报</td>\n",
       "      <td>adj</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>早衰</td>\n",
       "      <td>adj</td>\n",
       "      <td>NE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>责备</td>\n",
       "      <td>verb</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>贼眼</td>\n",
       "      <td>noun</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   词语  词性种类 情感分类  强度\n",
       "0  脏乱   adj   NN   7\n",
       "1  糟报   adj   NN   5\n",
       "2  早衰   adj   NE   5\n",
       "3  责备  verb   NN   5\n",
       "4  贼眼  noun   NN   5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlut = pd.read_excel('/Users/jiaojiao/Downloads/DLUT-Emotion-Lexicon.xlsx', usecols=['词语', '词性种类', '情感分类', '强度'])\n",
    "dlut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5305086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#整理情感词典\n",
    "Happy, Good, Surprise, Anger, Sad, Fear, Disgust  = [], [], [], [], [], [], []\n",
    "\n",
    "for idx, row in dlut.iterrows():\n",
    "    if row['情感分类'] in ['PA', 'PE']:\n",
    "        Happy.append(row['词语'])\n",
    "    if row['情感分类'] in ['PD', 'PH', 'PG', 'PB', 'PK']:\n",
    "        Good.append(row['词语']) \n",
    "    if row['情感分类'] in ['PC']:\n",
    "        Surprise.append(row['词语'])     \n",
    "    if row['情感分类'] in ['NA']:\n",
    "        Anger.append(row['词语'])    \n",
    "    if row['情感分类'] in ['NB', 'NJ', 'NH', 'PF']:\n",
    "        Sad.append(row['词语'])\n",
    "    if row['情感分类'] in ['NI', 'NC', 'NG']:\n",
    "        Fear.append(row['词语'])\n",
    "    if row['情感分类'] in ['NE', 'ND', 'NN', 'NK', 'NL']:\n",
    "        Disgust.append(row['词语'])\n",
    "Positive = Happy + Good + Surprise\n",
    "Negative = Anger + Sad + Fear + Disgust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f6af6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_dlut</th>\n",
       "      <th>positive_dlut</th>\n",
       "      <th>negative_dlut</th>\n",
       "      <th>anger_dlut</th>\n",
       "      <th>disgust_dlut</th>\n",
       "      <th>fear_dlut</th>\n",
       "      <th>good_dlut</th>\n",
       "      <th>sadness_dlut</th>\n",
       "      <th>surprise_dlut</th>\n",
       "      <th>happy_dlut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  length_dlut positive_dlut negative_dlut anger_dlut disgust_dlut fear_dlut  \\\n",
       "0          30             0             0          0            0         0   \n",
       "1         129             9             6          0            3         2   \n",
       "2          11             0             0          0            0         0   \n",
       "3         155             7             6          0            5         0   \n",
       "4         433            34            16          0           14         1   \n",
       "\n",
       "  good_dlut sadness_dlut surprise_dlut happy_dlut  \n",
       "0         0            0             0          0  \n",
       "1         9            1             0          0  \n",
       "2         0            0             0          0  \n",
       "3         7            1             0          0  \n",
       "4        23            1             0         11  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_dlut = pd.DataFrame(columns=['length_dlut', 'positive_dlut', 'negative_dlut',\n",
    "                                'anger_dlut', 'disgust_dlut', 'fear_dlut', 'good_dlut',\n",
    "                                'sadness_dlut', 'surprise_dlut', 'happy_dlut'])\n",
    "\n",
    "for dc in df_chn.index:\n",
    "    positive, negative, anger, disgust, fear, sad, surprise, good, happy = 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    wordlist = list(jieba.cut(df_chn['广告文本'][dc]))\n",
    "    wordset = set(wordlist)\n",
    "    wordfreq = []\n",
    "    for word in wordset:\n",
    "        freq = wordlist.count(word)\n",
    "        if word in Positive:\n",
    "            positive += freq\n",
    "        if word in Negative:\n",
    "            negative += freq\n",
    "        if word in Anger:\n",
    "            anger += freq\n",
    "        if word in Disgust:\n",
    "            disgust += freq\n",
    "        if word in Fear:\n",
    "            fear += freq\n",
    "        if word in Sad:\n",
    "            sad += freq\n",
    "        if word in Surprise:\n",
    "            surprise += freq\n",
    "        if word in Good:\n",
    "            good += freq\n",
    "        if word in Happy:\n",
    "            happy += freq\n",
    "            \n",
    "    emotion_info = {\n",
    "        'length_dlut': len(wordlist),\n",
    "        'positive_dlut': positive,\n",
    "        'negative_dlut': negative,\n",
    "        'anger_dlut': anger,\n",
    "        'disgust_dlut': disgust,\n",
    "        'fear_dlut': fear,\n",
    "        'good_dlut': good,\n",
    "        'sadness_dlut': sad,\n",
    "        'surprise_dlut': surprise,\n",
    "        'happy_dlut': happy\n",
    "    }\n",
    "    \n",
    "    emo_info = pd.DataFrame([emotion_info])\n",
    "    emo_dlut = pd.concat([emo_dlut, emo_info], ignore_index=True)\n",
    "    \n",
    "emo_dlut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1c6d033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>商品名称</th>\n",
       "      <th>商品类别</th>\n",
       "      <th>出版年</th>\n",
       "      <th>广告文本</th>\n",
       "      <th>广告标题</th>\n",
       "      <th>length_nrc</th>\n",
       "      <th>positive_nrc</th>\n",
       "      <th>negative_nrc</th>\n",
       "      <th>anger_nrc</th>\n",
       "      <th>...</th>\n",
       "      <th>length_dlut</th>\n",
       "      <th>positive_dlut</th>\n",
       "      <th>negative_dlut</th>\n",
       "      <th>anger_dlut</th>\n",
       "      <th>disgust_dlut</th>\n",
       "      <th>fear_dlut</th>\n",
       "      <th>good_dlut</th>\n",
       "      <th>sadness_dlut</th>\n",
       "      <th>surprise_dlut</th>\n",
       "      <th>happy_dlut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>五华牌香烟[May Blossom]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1932</td>\n",
       "      <td>兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...</td>\n",
       "      <td>五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5627</td>\n",
       "      <td>韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1918</td>\n",
       "      <td>讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...</td>\n",
       "      <td>韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'</td>\n",
       "      <td>129</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13532</td>\n",
       "      <td>大炮台香烟[Three Castles Cigarettes]</td>\n",
       "      <td>烟草制品</td>\n",
       "      <td>1935</td>\n",
       "      <td>香味馥郁,不让名花 另有三炮台出售</td>\n",
       "      <td>大炮台香烟,\"香味馥郁 不让名花\"</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>婴孩自己药片[Baby's Own]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1930</td>\n",
       "      <td>差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...</td>\n",
       "      <td>婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3146</td>\n",
       "      <td>亚士北罗药片[Aspro]</td>\n",
       "      <td>药品</td>\n",
       "      <td>1933</td>\n",
       "      <td>何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...</td>\n",
       "      <td>亚士北罗药片,\"妇女之腻友\"</td>\n",
       "      <td>433</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>433</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              商品名称  商品类别   出版年  \\\n",
       "0   1596                                五华牌香烟[May Blossom]  烟草制品  1932   \n",
       "1   5627  韦廉士红色清导丸[Dr.Willams' Pink Pills For Pale People]    药品  1918   \n",
       "2  13532                   大炮台香烟[Three Castles Cigarettes]  烟草制品  1935   \n",
       "3   1133                                婴孩自己药片[Baby's Own]    药品  1930   \n",
       "4   3146                                     亚士北罗药片[Aspro]    药品  1933   \n",
       "\n",
       "                                                广告文本  \\\n",
       "0  兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟  二十枝装每包售国币大洋二角 五十枝装每罐售国币...   \n",
       "1  讲求卫生为人生本性天理固然也 人生首贵逐日大便通畅有序为天然所当如此也如若大便不利大肠阻塞则...   \n",
       "2                                  香味馥郁,不让名花 另有三炮台出售   \n",
       "3  差肩儿女 秀慧康强 闽有佳音讃羡婴孩自己药片 每年此际小儿患肠胃病者甚多而尤以南方各地天气翳...   \n",
       "4  何以亚士北罗是妇女们的腻友？各国妇女力证亚士北罗药片是她们最需要的药物！为什么？她们的经验知...   \n",
       "\n",
       "                              广告标题 length_nrc positive_nrc negative_nrc  \\\n",
       "0    五华牌香烟,\"兰勃脱白脱勒公司 五华牌香烟 佛及尼埃香烟\"         30            1            2   \n",
       "1        韦廉士红色清导丸:'讲求卫生为人生本性天理固然也'        129            7           11   \n",
       "2                大炮台香烟,\"香味馥郁 不让名花\"         11            0            0   \n",
       "3  婴孩自己药片,\"差肩儿女 秀慧康强 闽有佳音赞美婴孩自己药片\"        155            7            7   \n",
       "4                   亚士北罗药片,\"妇女之腻友\"        433           19           14   \n",
       "\n",
       "  anger_nrc  ... length_dlut positive_dlut negative_dlut anger_dlut  \\\n",
       "0         0  ...          30             0             0          0   \n",
       "1         1  ...         129             9             6          0   \n",
       "2         0  ...          11             0             0          0   \n",
       "3         2  ...         155             7             6          0   \n",
       "4         4  ...         433            34            16          0   \n",
       "\n",
       "  disgust_dlut fear_dlut good_dlut sadness_dlut surprise_dlut happy_dlut  \n",
       "0            0         0         0            0             0          0  \n",
       "1            3         2         9            1             0          0  \n",
       "2            0         0         0            0             0          0  \n",
       "3            5         0         7            1             0          0  \n",
       "4           14         1        23            1             0         11  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chn = pd.concat([df_chn, emo_dlut], axis=1)\n",
    "df_chn.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
